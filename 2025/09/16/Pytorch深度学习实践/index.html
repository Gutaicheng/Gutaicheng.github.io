

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/tubiao2.png">
  <link rel="icon" href="/img/tubiao2.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="GuTaicheng">
  <meta name="keywords" content="博客, 学习, Java">
  
    <meta name="description" content="本博客是根据Bilibil《PyTorch深度学习实践》完结合集_哔哩哔哩_bilibili所做的笔记 名词解释 数据集(Data Set)  训练集(Traing Set)  已知输入x和输出y，用于训练模型  训练集可在分一部分出来作为开发集，用于评估模型的泛化能力，防止过拟合    测试集(Test Set)  只知道输入x     过拟合(Overfitting)  是模型在训练集">
<meta property="og:type" content="article">
<meta property="og:title" content="Pytorch深度学习实践">
<meta property="og:url" content="https://blog.gutaicheng.top/2025/09/16/Pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/index.html">
<meta property="og:site_name" content="GuTaicheng&#39;s Blog">
<meta property="og:description" content="本博客是根据Bilibil《PyTorch深度学习实践》完结合集_哔哩哔哩_bilibili所做的笔记 名词解释 数据集(Data Set)  训练集(Traing Set)  已知输入x和输出y，用于训练模型  训练集可在分一部分出来作为开发集，用于评估模型的泛化能力，防止过拟合    测试集(Test Set)  只知道输入x     过拟合(Overfitting)  是模型在训练集">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250910122424933.png">
<meta property="article:published_time" content="2025-09-15T16:50:00.000Z">
<meta property="article:modified_time" content="2025-09-19T09:54:43.815Z">
<meta property="article:author" content="GuTaicheng">
<meta property="article:tag" content="Pytorch - 深度学习">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250910122424933.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Pytorch深度学习实践 - GuTaicheng&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"blog.gutaicheng.top","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":21404155,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  
    <!-- 51.la Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript('//js.users.51.la/21404155.js');
      }
    </script>
  

  

  



  
  <meta name="referrer" content="never">
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>GuTaicheng</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Pytorch深度学习实践"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-09-16 00:50" pubdate>
          2025年9月16日 凌晨
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          9.9k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          83 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Pytorch深度学习实践</h1>
            
            
              <div class="markdown-body">
                
                <meta name="referrer" content="no-referrer" />



<p>本博客是根据Bilibil<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Y7411d7Ys/">《PyTorch深度学习实践》完结合集_哔哩哔哩_bilibili</a>所做的笔记</p>
<h1 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h1><ul>
<li><p>数据集(Data Set)</p>
<ul>
<li><p>训练集(Traing Set)</p>
<ul>
<li><p>已知<strong>输入x</strong>和<strong>输出y</strong>，用于训练模型</p>
</li>
<li><p>训练集可在分一部分出来作为<strong>开发集</strong>，用于评估模型的泛化能力，防止过拟合</p>
</li>
</ul>
</li>
<li><p>测试集(Test Set)</p>
<ul>
<li>只知道<strong>输入x</strong></li>
</ul>
</li>
</ul>
</li>
<li><p>过拟合(Overfitting)</p>
<ul>
<li>是模型在训练集上表现很好，但在新数据上表现很差</li>
<li>但它并没有真正学到数据背后的普遍规律，而是把训练数据中的<strong>所有特征，包括噪声</strong>，都当作了学习目标。当它遇到<strong>新数据</strong>时，它的表现会急剧下降，预测结果非常不准确</li>
</ul>
</li>
<li><p>泛化(Generalization)</p>
<ul>
<li>泛化是机器学习模型的真正目标，它是指模型在<strong>未见过的新数据</strong>上的表现能力</li>
</ul>
</li>
</ul>
<h1 id="线性模型-Linear-Model"><a href="#线性模型-Linear-Model" class="headerlink" title="线性模型(Linear Model)"></a>线性模型(Linear Model)</h1><p>拿到数据集，先试着用线性模型<strong>试一下</strong>，即找到一个<strong>权重w和截距b</strong>，使得训练集满足：</p>
<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250915205727712.png" srcset="/img/loading.gif" lazyload alt="image-20250915205727712"></p>
<ul>
<li><p><strong>ŷ</strong>读作y_hat，表示预测的值，并不是准确值</p>
</li>
<li><p>为了方便学习，这里选择简化模型，将截距b去掉</p>
<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250915210137135.png" srcset="/img/loading.gif" lazyload alt="image-20250915210137135"></p>
</li>
</ul>
<p>所以线性模型的关键是找到一个合适的<strong>权重w</strong>，而什么叫做”合适呢“？即误差小。</p>
<ul>
<li><p>初始数据集可能并不是严格的在直线上的点集，会是离散的，而我们预设的线性模型是一条严格的直线</p>
<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250915211004528.png" srcset="/img/loading.gif" lazyload alt="image-20250915211004528"></p>
</li>
<li><p>而预测的**ŷ(a)<strong>会和对应的同一个横坐标a的真实值</strong>y(a)**有差值</p>
<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250915211334561.png" srcset="/img/loading.gif" lazyload alt="image-20250915211334561"></p>
</li>
<li><p>但是由于差值有正有负，所以对差值进行<strong>求平方</strong>（当然也有其他方法，取绝对值等，<strong>但是平方对于误差大的惩罚越大</strong>）即可消去负值影响，而这些平方值即为<strong>损失(loss)</strong></p>
<ul>
<li>loss只是针对单独一个样本的</li>
</ul>
<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250915212029351.png" srcset="/img/loading.gif" lazyload alt="image-20250915212029351"></p>
</li>
<li><p>得到单独样本<strong>损失</strong>后，对所有样本的损失进行<strong>求和</strong>，再取<strong>平均值</strong>，即得到训练集的<strong>误差(Error)</strong></p>
<ul>
<li>采用平方来计算这种方法得到的误差叫做<strong>平均平方误差</strong>或者<strong>均方误差</strong>（Mean Squared Error, <strong>MSE</strong>）</li>
<li>误差(Error)是针对训练集training set的</li>
</ul>
<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250915213243814.png" srcset="/img/loading.gif" lazyload alt="image-20250915213243814"></p>
<blockquote>
<p>[!IMPORTANT]</p>
<p>注意：<br>损失函数<strong>loss function</strong>的定义：</p>
<p>并不是上面的 loss &#x3D; 差值的平方</p>
<p>而是最终求和后的平均计算，比如MSE的公式</p>
</blockquote>
</li>
<li><p>最终找到一个误差最小的<strong>权重w</strong>，就是线性模型的关键。</p>
<p>比如下图的数据集与权重选择</p>
<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250915213736813.png" srcset="/img/loading.gif" lazyload alt="image-20250915213736813"></p>
</li>
</ul>
<h2 id="穷举法找权重w"><a href="#穷举法找权重w" class="headerlink" title="穷举法找权重w"></a>穷举法找权重w</h2><ul>
<li><p>先随机找一个<strong>大的步长</strong>范围，尝试找到一个<strong>可能（可能有增或减的趋势）</strong>存在最小权重的范围</p>
</li>
<li><p>再在这个范围内，<strong>缩短步长</strong>，以此找到产生最小误差的权重</p>
<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250915214623127.png" srcset="/img/loading.gif" lazyload alt="image-20250915214623127"></p>
</li>
<li><p>代码演示，绘制图如上</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入计算和绘图用的包</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 定义数据集</span><br>x_data = [<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>] <span class="hljs-comment"># 输入</span><br>y_data = [<span class="hljs-number">2.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">6.0</span>] <span class="hljs-comment"># 输出</span><br><br><span class="hljs-comment"># 用于计算 y 的预测值</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">x, w</span>):<br>    <span class="hljs-keyword">return</span> x * w<br><br><span class="hljs-comment"># 单个样本的损失loss</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">x, y, w</span>):<br>    y_pred = forward(x, w)<br>    <span class="hljs-keyword">return</span> (y_pred - y) * (y_pred - y)<br><br><span class="hljs-comment"># MES损失函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">MSE</span>(<span class="hljs-params">xd, yd, w</span>):<br>    loss_sum = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> x_val, y_val <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(xd, yd):<br>        loss_sum += loss(x_val, y_val, w)<br>    <span class="hljs-keyword">return</span> loss_sum / <span class="hljs-built_in">len</span>(xd)<br><br><span class="hljs-comment"># 权重值列表</span><br>w_list = []<br><span class="hljs-comment"># MSE误差列表</span><br>mse_list = []<br><br><span class="hljs-comment"># w权重取值范围在 [0.0, 4.0], 步长间隔为 0.1</span><br><span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> np.arange(<span class="hljs-number">0.0</span>, <span class="hljs-number">4.1</span>, <span class="hljs-number">0.1</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;w=&#x27;</span>, w)<br>    mes = MSE(x_data, y_data, w)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;MSE=&#x27;</span>, mes)<br>    w_list.append(w)<br>    mse_list.append(mes)<br><br>plt.plot(w_list, mse_list)<br>plt.ylabel(<span class="hljs-string">&#x27;Loss&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;w&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>
</li>
<li><p>非简化版本，基本模型：<strong>ŷ &#x3D; x*w + b</strong>;   w，b，mse，三维绘制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入计算和绘图用的包</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> cm<br><span class="hljs-keyword">from</span> mpl_toolkits.mplot3d <span class="hljs-keyword">import</span> Axes3D  <span class="hljs-comment"># 导入3D绘图模块</span><br><br><span class="hljs-comment"># --- 添加这三行，设置中文显示 ---</span><br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]  <span class="hljs-comment"># 指定默认字体为黑体</span><br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span>     <span class="hljs-comment"># 解决保存图像时负号 &#x27;-&#x27; 显示为方块的问题</span><br><span class="hljs-comment"># --------------------------------</span><br><br><span class="hljs-comment"># 定义数据集</span><br>x_data = [<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>] <span class="hljs-comment"># 输入</span><br>y_data = [<span class="hljs-number">2.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">6.0</span>] <span class="hljs-comment"># 输出</span><br><br><span class="hljs-comment"># 用于计算 y 的预测值</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">x, w, b</span>):<br>    <span class="hljs-keyword">return</span> x * w + b<br><br><span class="hljs-comment"># 单个样本的损失loss</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">x, y, w, b</span>):<br>    y_pred = forward(x, w, b)<br>    <span class="hljs-keyword">return</span> (y_pred - y) * (y_pred - y)<br><br><span class="hljs-comment"># MES损失函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">MSE</span>(<span class="hljs-params">xd, yd, w, b</span>):<br>    loss_sum = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> x_val, y_val <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(xd, yd):<br>        loss_val = loss(x_val, y_val, w, b)<br>        loss_sum += loss_val<br>    <span class="hljs-keyword">return</span> loss_sum / <span class="hljs-built_in">len</span>(xd)<br><br><span class="hljs-comment"># 定义 w 和 b 的取值范围</span><br><span class="hljs-comment"># arange是 Numpy 库中的一个函数，它类似于 Python 内置的 range() 函数，但主要用于创建包含浮点数的数组。</span><br><span class="hljs-comment"># 第一行代码会创建一个从 0.0 开始，到 4.1 结束（不包含 4.1），步长为 0.1 的一维数组。</span><br><span class="hljs-comment"># 第二行代码会创建一个从 -2.0 到 2.1 结束（不包含 2.1），步长为 0.1 的数组。</span><br>w_range = np.arange(<span class="hljs-number">0.0</span>, <span class="hljs-number">4.1</span>, <span class="hljs-number">0.1</span>)<br>b_range = np.arange(-<span class="hljs-number">2.0</span>, <span class="hljs-number">2.1</span>, <span class="hljs-number">0.1</span>)<br><br><span class="hljs-comment"># 创建一个用于存储 MSE 值的二维网格</span><br><span class="hljs-comment"># 分别创建两个矩阵 w_values 和 b_values， 用于绘制 3D 图时的 x, y 坐标</span><br><span class="hljs-comment"># w_values：这个矩阵的每一 行 都是 w_range 数组的重复</span><br><span class="hljs-comment"># b_values：这个矩阵的每一 列 都是 b_range 数组的重复。</span><br><span class="hljs-comment"># 故此将两个矩阵重叠，相同位置的两个元素(w,b)就代表了所有可能的点</span><br>w_values, b_values = np.meshgrid(w_range, b_range)<br><br><span class="hljs-comment"># 创建全零矩阵保存所有的损失值</span><br><span class="hljs-comment"># np.zeros_like()：这个函数会创建一个与 w_values 形状完全相同（即行列数一样）的全零矩阵。</span><br>mse_values = np.zeros_like(w_values)<br><br><span class="hljs-comment"># 遍历 w 和 b 的所有组合，计算并存储 MSE 值</span><br><span class="hljs-keyword">for</span> i, w <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(w_range):<br>    <span class="hljs-keyword">for</span> j, b <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(b_range):<br>        mse_values[j, i] = MSE(x_data, y_data, w, b)<br><br><span class="hljs-comment"># 绘制 3D 图像</span><br><span class="hljs-comment"># figure函数 创建一个新的图形窗口</span><br><span class="hljs-comment"># figsize 参数设置了窗口的尺寸（长和宽），当然figsize不填也行</span><br>fig = plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">8</span>))<br><br><span class="hljs-comment"># add_subplot()函数 在图形窗口中添加一个子图（subplot）</span><br><span class="hljs-comment"># 111 表示将图形窗口划分为 1x1 的网格，并在第 1 个子图上绘图</span><br><span class="hljs-comment"># 下列方式是简便的工厂模式。告诉 add_subplot 函数你想要一个 3D 坐标系，它就会在后台为你创建一个 Axes3D 对象。</span><br><span class="hljs-comment"># projection=&#x27;3d&#x27; 告诉 Matplotlib 要创建一个 3D 坐标系，而不是默认的 2D 坐标系</span><br><span class="hljs-comment"># 这种方式代码更简洁，但可能会让 IDE 产生误判，导致最开始的import显示未引用</span><br>ax = fig.add_subplot(<span class="hljs-number">111</span>, projection=<span class="hljs-string">&#x27;3d&#x27;</span>)<br><br><span class="hljs-comment"># 绘制曲面图</span><br><span class="hljs-comment"># plot_surface() 绘制曲面图函数</span><br><span class="hljs-comment"># w_values, b_values, mse_values：这三个参数是 3D 表面图的三个坐标轴：x 轴、y 轴和 z 轴</span><br><span class="hljs-comment"># cmap=cm.viridis：cmap 是 &quot;colormap&quot;（颜色映射）的缩写，它定义了曲面图的颜色方案。viridis 是一种常用的、颜色渐变平滑的方案</span><br><span class="hljs-comment"># alpha=0.9：alpha 设置了曲面的透明度，0.0 是完全透明，1.0 是完全不透明。</span><br>surf = ax.plot_surface(w_values, b_values, mse_values, cmap=cm.viridis, alpha=<span class="hljs-number">0.9</span>)<br><br><span class="hljs-comment"># 设置图像标题和标签</span><br>ax.set_title(<span class="hljs-string">&quot;3D 损失函数（MSE）表面图&quot;</span>, fontsize=<span class="hljs-number">16</span>)<br>ax.set_xlabel(<span class="hljs-string">&#x27;w (权重)&#x27;</span>, fontsize=<span class="hljs-number">12</span>)<br>ax.set_ylabel(<span class="hljs-string">&#x27;b (截距)&#x27;</span>, fontsize=<span class="hljs-number">12</span>)<br>ax.set_zlabel(<span class="hljs-string">&#x27;MSE (损失)&#x27;</span>, fontsize=<span class="hljs-number">12</span>)<br><br><span class="hljs-comment"># 添加颜色条</span><br>fig.colorbar(surf, shrink=<span class="hljs-number">0.5</span>, aspect=<span class="hljs-number">5</span>)<br><br><span class="hljs-comment"># 找到损失函数的最小值点（理论上，w=2.0, b=0.0 时损失为0）</span><br><span class="hljs-comment"># np.argmin()：这个函数返回一个数组中最小值元素的索引</span><br><span class="hljs-comment"># axis=None：忽略数组的维度，而是在整个二维矩阵中寻找唯一的一个最小值。它会返回这个最小值在一维展平（flattened）后的数组中的索引</span><br><span class="hljs-comment"># axis=0：表示沿着列（columns）进行操作，有几列就会返回几个元素的数组</span><br><span class="hljs-comment"># axis=1：表示沿着行（rows）进行操作，有几行就返回几个元素的数组</span><br><span class="hljs-comment"># 例如取None时 mse_values 矩阵是 [[10, 20], [3, 40]]，那么它的最小值是 3</span><br><span class="hljs-comment"># 在一维展平后，数组变为 [10, 20, 3, 40]，3 的索引是 2。所以 np.argmin() 会返回 2</span><br><span class="hljs-comment"># np.unravel_index()：反向将一维数组的索引转换为二维，但是要填入参数 shape：即我们传入的是原始矩阵的形状</span><br><span class="hljs-comment"># 最后返回的是二维坐标 (w, b)</span><br>min_mse_index = np.unravel_index(np.argmin(mse_values, axis=<span class="hljs-literal">None</span>), mse_values.shape)<br><span class="hljs-comment"># 在两个矩阵中获取最小MES对应的具体值</span><br>min_b = b_values[min_mse_index]<br>min_w = w_values[min_mse_index]<br><br><span class="hljs-comment"># 在图上标记最小值点</span><br><span class="hljs-comment"># 参数依次对应：颜色、形状、大小、标签说明</span><br>ax.scatter(min_w, min_b, mse_values.<span class="hljs-built_in">min</span>(), color=<span class="hljs-string">&#x27;red&#x27;</span>, marker=<span class="hljs-string">&#x27;o&#x27;</span>, s=<span class="hljs-number">100</span>,<br>           label=<span class="hljs-string">f&#x27;最小损失点\n(w=<span class="hljs-subst">&#123;min_w:<span class="hljs-number">.2</span>f&#125;</span>, b=<span class="hljs-subst">&#123;min_b:<span class="hljs-number">.2</span>f&#125;</span>)&#x27;</span>)<br><br><span class="hljs-comment"># 显示散点图的图例</span><br>ax.legend()<br><br><span class="hljs-comment"># 调整视角以获得更好的可视化效果</span><br><span class="hljs-comment"># elev 是仰角，azim 是方位角</span><br>ax.view_init(elev=<span class="hljs-number">20</span>, azim=-<span class="hljs-number">120</span>)<br><br><span class="hljs-comment"># 显示最终绘制好的图形窗口</span><br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250917225211998.png" srcset="/img/loading.gif" lazyload alt="image-20250917225211998"></p>
</li>
</ul>
<h2 id="分治法求取多维权重（被舍弃的方法）"><a href="#分治法求取多维权重（被舍弃的方法）" class="headerlink" title="分治法求取多维权重（被舍弃的方法）"></a>分治法求取多维权重（被舍弃的方法）</h2><ul>
<li>当涉及的权重有多个时，以二维为例，假设每个权重取100个值，则一共有100^2种组合（维度的诅咒）</li>
<li>首先取一个稀疏点阵，比如 4 x 4 的稀疏点阵，求取这16个点的MSE值</li>
<li>再选取MSE最小的那个点，在它的周围再次取一个 4 x 4 的稀疏点阵，重复计算</li>
<li>以此试图找到使得MSE最小的权重组合</li>
</ul>
<blockquote>
<p>[!TIP]</p>
<p>弊端：为什么被舍弃</p>
<ul>
<li>机器学习中的优化问题（如线性回归、神经网络训练）通常是<strong>连续可导</strong>的，不适合用分治法分成若干个小问题</li>
</ul>
</blockquote>
<h2 id="梯度下降算法（推荐）"><a href="#梯度下降算法（推荐）" class="headerlink" title="梯度下降算法（推荐）"></a>梯度下降算法（推荐）</h2><ul>
<li>先随机取一个权重组合</li>
<li>计算取该组合时，损失函数在此<strong>对权重</strong>的导数（也叫<strong>梯度</strong>）；<ul>
<li>导数为正，代表往右递增，往左递减</li>
<li>导数为负，代表往右递减，往左递增</li>
</ul>
</li>
<li>以导数为基准，对权重进行迭代，而不是像穷举法那样以相同的步长进行迭代</li>
</ul>
<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250918165530078.png" srcset="/img/loading.gif" lazyload alt="一维权重求导过程"></p>
<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250918165604233.png" srcset="/img/loading.gif" lazyload alt="权重迭代公式"></p>
<ul>
<li>权重迭代公式中的 <strong>α</strong> 的名称叫做<strong>学习率</strong>，是一个很重要的参数，相当于穷举法中的步幅<ul>
<li>它不是通过训练学习出来的，而是需要我们在训练前手动设置。选择一个合适的学习率是训练一个高性能模型的关键一步。</li>
<li>步子迈得太大，可能会直接<strong>跳过</strong>损失函数的最小值点，甚至在“山谷”的两侧来回震荡，导致损失值越来越大，永远无法收敛。这就像你下山时，每一步都跨得太大，结果不是跑到山脚下，而是跳到了对面的悬崖上。</li>
<li>步子迈得太小，虽然能够保证每一步都朝着正确的方向前进，但<strong>收敛速度会非常慢</strong>，需要进行大量的迭代才能到达最小值。这会极大地增加训练所需的时间和计算资源。这就像你在下山时，每一步都只挪动一小段距离，要花很长时间才能到达山脚。</li>
</ul>
</li>
</ul>
<h3 id="梯度下降算法的问题"><a href="#梯度下降算法的问题" class="headerlink" title="梯度下降算法的问题"></a>梯度下降算法的问题</h3><ul>
<li>同样是局部最优解，但是比分治法处理的更平滑，也更容易克服，比如我采用多轮次，每轮选取不同的初始点。</li>
<li>鞍点问题：<ul>
<li>一维权重时，也就是驻点，即导数为零的点，会导致迭代停止</li>
<li>多维权重时，可能会形成像马鞍（薯片）一样的曲面，从某个方向看，这个点是<strong>局部最高点</strong>（比如马鞍的前后方向），从另一个方向看，这个点又是<strong>局部最低点</strong>（比如马鞍的左右方向）。</li>
</ul>
</li>
</ul>
<h3 id="简化模型使用梯度下降算法预测权重（无截距）"><a href="#简化模型使用梯度下降算法预测权重（无截距）" class="headerlink" title="简化模型使用梯度下降算法预测权重（无截距）"></a>简化模型使用梯度下降算法预测权重（无截距）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入计算和绘图用的包</span><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 定义数据集</span><br>x_data = [<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>] <span class="hljs-comment"># 输入</span><br>y_data = [<span class="hljs-number">2.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">6.0</span>] <span class="hljs-comment"># 输出</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">x, w</span>):<br>    <span class="hljs-keyword">return</span> x*w<br><br><span class="hljs-comment"># 单个样本的损失loss</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">x, y, w</span>):<br>    y_pred = forward(x, w)<br>    <span class="hljs-keyword">return</span> (y_pred - y) * (y_pred - y)<br><br><span class="hljs-comment"># MSE损失函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">MSE</span>(<span class="hljs-params">xd, yd, w</span>):<br>    loss_sum = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> x_val, y_val <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(xd, yd):<br>        loss_sum += loss(x_val, y_val, w)<br>    <span class="hljs-keyword">return</span> loss_sum / <span class="hljs-built_in">len</span>(xd)<br><br><span class="hljs-comment"># 定义梯度函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient</span>(<span class="hljs-params">xd, yd, w</span>):<br>    grad_sum = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> x_val, y_val <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(xd, yd):<br>        grad_sum += <span class="hljs-number">2</span> * x_val * (x_val * w - y_val)<br>    <span class="hljs-keyword">return</span> grad_sum / <span class="hljs-built_in">len</span>(xd)<br><br><span class="hljs-comment"># 初始随机权重</span><br>w = <span class="hljs-number">1.0</span><br><span class="hljs-comment"># 定义学习率</span><br>a = <span class="hljs-number">0.01</span><br><span class="hljs-comment"># 轮次值列表</span><br>epoch_list = []<br><span class="hljs-comment"># MSE误差列表</span><br>mse_list = []<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练前的预测值 x =&#x27;</span>, <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;y =&#x27;</span>,  forward(<span class="hljs-number">4</span>, w))<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    mes_val = MSE(x_data, y_data, w)<br>    mse_list.append(mes_val)<br>    grad_val = gradient(x_data, y_data, w)<br>    w -= a * grad_val<br>    epoch_list.append(epoch)<br>    <span class="hljs-comment"># 详细值</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;epoch: <span class="hljs-subst">&#123;epoch&#125;</span>, w: <span class="hljs-subst">&#123;w&#125;</span>, mes: <span class="hljs-subst">&#123;mes_val&#125;</span>&quot;</span>)<br>    <span class="hljs-comment"># 保留两位小数的值</span><br>    <span class="hljs-comment"># print(f&quot;epoch: &#123;epoch&#125;, w: &#123;round(w, 2)&#125;, mes: &#123;round(mes_val, 2)&#125;&quot;)</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练后的预测值 x =&#x27;</span>, <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;y =&#x27;</span>, forward(<span class="hljs-number">4</span>, w))<br><br>plt.plot(epoch_list, mse_list)<br>plt.xlabel(<span class="hljs-string">&#x27;epoch&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;MES&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250918204114132.png" srcset="/img/loading.gif" lazyload alt="image-20250918204114132"></p>
<h3 id="随机梯度下降算法-SGD"><a href="#随机梯度下降算法-SGD" class="headerlink" title="随机梯度下降算法(SGD)"></a>随机梯度下降算法(SGD)</h3><ul>
<li><p>上述的梯度算法，对于每次权重迭代的大小是由<strong>所有数据的损失汇总取平均值得到的误差</strong>来计算的，这样的方式在遇到鞍点时可能会停滞不前</p>
</li>
<li><p>而随机梯度算法，权重的迭代大小是由<strong>随机取一个样本（也可以按照顺序随机，也叫顺序随机梯度算法），用其损失对权重求导</strong>，这样的方式可能可以跨过鞍点，使权重继续前进</p>
<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250918213038164.png" srcset="/img/loading.gif" lazyload alt="image-20250918213038164"></p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入计算和绘图用的包</span><br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 定义数据集</span><br>x_data = [<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>]  <span class="hljs-comment"># 输入</span><br>y_data = [<span class="hljs-number">2.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">6.0</span>]  <span class="hljs-comment"># 输出</span><br><br><span class="hljs-comment"># 用于计算 y 的预测值</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">x, w</span>):<br>    <span class="hljs-keyword">return</span> x * w<br><br><span class="hljs-comment"># 单个样本的损失loss</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">x, y, w</span>):<br>    y_pred = forward(x, w)<br>    <span class="hljs-keyword">return</span> (y_pred - y) * (y_pred - y)<br><br><span class="hljs-comment"># 定义梯度函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient</span>(<span class="hljs-params">x, y, w</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">2</span> * x * (x * w - y)<br><br><span class="hljs-comment"># 初始化权重和学习率</span><br>w = <span class="hljs-number">1.0</span><br>a = <span class="hljs-number">0.01</span><br><br><span class="hljs-comment"># 用于记录每个轮次的平均损失</span><br>epochs_list = []<br>costs_list = []<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练前的预测值 x = 4, y =&#x27;</span>, forward(<span class="hljs-number">4</span>, w))<br><br><span class="hljs-comment"># 训练循环</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    <span class="hljs-comment"># 在每个轮次开始时，初始化总损失</span><br>    epoch_loss_sum = <span class="hljs-number">0</span><br><br>    <span class="hljs-comment"># 随机选择一个样本进行训练</span><br>    index = random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<span class="hljs-comment"># 这里是真随机</span><br>    x_val = x_data[index]<br>    y_val = y_data[index]<br><br>    <span class="hljs-comment"># 计算梯度并更新权重</span><br>    grad = gradient(x_val, y_val, w)<br>    w -= a * grad<br><br>    <span class="hljs-comment"># 计算当前样本的损失并累加到总损失中</span><br>    current_loss = loss(x_val, y_val, w)<br><br>    <span class="hljs-comment"># 因为是SGD，一个轮次只训练一个样本，所以直接记录当前损失即可</span><br>    epoch_loss = current_loss / <span class="hljs-number">1</span> <span class="hljs-comment"># loss的计算只是为了输出体现为0而已</span><br><br>    <span class="hljs-comment"># 打印当前轮次的信息</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Epoch: <span class="hljs-subst">&#123;epoch&#125;</span>, w = <span class="hljs-subst">&#123;w:<span class="hljs-number">.2</span>f&#125;</span>, loss = <span class="hljs-subst">&#123;epoch_loss:<span class="hljs-number">.2</span>f&#125;</span>&#x27;</span>)<br><br>    <span class="hljs-comment"># 记录每个轮次的平均损失和轮次数，用于绘图</span><br>    epochs_list.append(epoch)<br>    costs_list.append(epoch_loss)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练后的预测值 x = 4, y =&#x27;</span>, forward(<span class="hljs-number">4</span>, w))<br><br><span class="hljs-comment"># 绘制损失曲线</span><br>plt.plot(epochs_list, costs_list)<br>plt.ylabel(<span class="hljs-string">&#x27;Cost&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;Epoch&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>

<ul>
<li><p>输出结果（由于每次都取单独一个样本进行计算梯度，所以波动会很大，每次图像基本不一样）</p>
<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250918221902242.png" srcset="/img/loading.gif" lazyload alt="image-20250918221902242"></p>
</li>
</ul>
<h3 id="小批量梯度下降算法-Mini-BGD"><a href="#小批量梯度下降算法-Mini-BGD" class="headerlink" title="小批量梯度下降算法(Mini-BGD)"></a>小批量梯度下降算法(Mini-BGD)</h3><ul>
<li>现在普遍也称<strong>BGD</strong></li>
<li>比如训练集有8对数据，每个小批次为2，则会分为4个批次batch</li>
<li>每个轮次epoch，都会计算这四个批次batch的的<strong>小平均损失</strong>，并且<strong>累加取平均</strong>，作为当前轮次epoch的<strong>平均损失</strong><ul>
<li>简单说就是每个<strong>小batch</strong>里要计算一次<strong>平均</strong>，每个<strong>轮次</strong>也要计算<strong>一次平均</strong>损失</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 假设数据集有8组</span><br>x_data = np.array([<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">6.0</span>, <span class="hljs-number">7.0</span>, <span class="hljs-number">8.0</span>])<br>y_data = np.array([<span class="hljs-number">2.3</span>, <span class="hljs-number">4.1</span>, <span class="hljs-number">5.8</span>, <span class="hljs-number">8.4</span>, <span class="hljs-number">10.3</span>, <span class="hljs-number">11.7</span>, <span class="hljs-number">14.5</span>, <span class="hljs-number">15.9</span>])<br><br><span class="hljs-comment"># 用于计算 y 的预测值</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">x, w</span>):<br>    <span class="hljs-keyword">return</span> x * w<br><br><span class="hljs-comment"># 使用 NumPy 计算整个样本的平均损失</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">avg_loss</span>(<span class="hljs-params">x, y, w</span>):<br>    y_pred = forward(x, w)<br>    <span class="hljs-keyword">return</span> np.mean((y_pred - y) ** <span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># 使用 NumPy 计算整个Batch的平均梯度</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">avg_gradient</span>(<span class="hljs-params">x, y, w</span>):<br>    <span class="hljs-keyword">return</span> np.mean(<span class="hljs-number">2</span> * x * (x * w - y))<br><br><span class="hljs-comment"># 初始化</span><br>w = <span class="hljs-number">1.0</span> <span class="hljs-comment"># 权重</span><br>a = <span class="hljs-number">0.0001</span> <span class="hljs-comment"># 学习率</span><br>batch_size = <span class="hljs-number">2</span> <span class="hljs-comment"># 批次Batch大小</span><br>num_samples = <span class="hljs-built_in">len</span>(x_data) <span class="hljs-comment"># 数据总组数</span><br>num_batches = num_samples // batch_size  <span class="hljs-comment"># 批次Batch数量</span><br><br><span class="hljs-comment"># 轮次列表 与 轮次的平均损失列表</span><br>epochs_list = []<br>costs_list = []<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练前的预测值 x = 4, y =&#x27;</span>, forward(<span class="hljs-number">4</span>, w))<br><br><span class="hljs-comment"># 训练循环</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>):<br>    <span class="hljs-comment"># 第一步：打乱数据</span><br>    indices = np.random.permutation(num_samples) <span class="hljs-comment"># 生成一个包含从 0 到 num_samples-1 的随机排列数组</span><br>    <span class="hljs-comment"># 每个轮次的 数据顺序都不同</span><br>    shuffled_x = x_data[indices]<br>    shuffled_y = y_data[indices]<br><br>    <span class="hljs-comment"># 第二步：创建批次Batch并循环</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_batches):<br>        <span class="hljs-comment"># 得到当前批次Batch的 起始 和 终止 索引</span><br>        start_index = i * batch_size<br>        end_index = start_index + batch_size<br>        <span class="hljs-comment"># 获取当前批次Batch的数据</span><br>        batch_x = shuffled_x[start_index:end_index]<br>        batch_y = shuffled_y[start_index:end_index]<br><br>        <span class="hljs-comment"># 计算当前批次Batch的平均梯度</span><br>        avg_batch_grad = avg_gradient(batch_x, batch_y, w)<br><br>        <span class="hljs-comment"># 更新权重</span><br>        w -= a * avg_batch_grad<br><br>    <span class="hljs-comment"># 计算并记录当前轮次（epoch）的平均损失</span><br>    avg_epoch_loss = avg_loss(x_data, y_data, w)<br><br>    <span class="hljs-comment"># 记录 当前轮次 和 当前轮次 的平均损失至数组方便绘图</span><br>    epochs_list.append(epoch)<br>    costs_list.append(avg_epoch_loss)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Epoch: <span class="hljs-subst">&#123;epoch&#125;</span>, w = <span class="hljs-subst">&#123;w&#125;</span>, avg_loss = <span class="hljs-subst">&#123;avg_epoch_loss&#125;</span>&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;训练后的预测值 x = 4, y =&#x27;</span>, forward(<span class="hljs-number">4</span>, w))<br><br><span class="hljs-comment"># 绘制损失曲线</span><br>plt.plot(epochs_list, costs_list)<br>plt.ylabel(<span class="hljs-string">&#x27;Cost&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;Epoch&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>

<p><img src="https://gitee.com/Gu-taicheng/image/raw/master/img/image-20250919174947709.png" srcset="/img/loading.gif" lazyload alt="image-20250919174947709"></p>
<ul>
<li>上述代码在求取平均值时采用了**np.mean()**的方法，使代码更简洁。</li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="category-chain-item">深度学习</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Pytorch-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">#Pytorch - 深度学习</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Pytorch深度学习实践</div>
      <div>https://blog.gutaicheng.top/2025/09/16/Pytorch深度学习实践/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>GuTaicheng</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年9月16日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/09/16/Conda%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/" title="Conda使用教程">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Conda使用教程</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/09/10/Pytorch%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/" title="Pytorch环境安装教程">
                        <span class="hidden-mobile">Pytorch环境安装教程</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.4.17/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"Mm7zXkSdUNoJGtCjXx5EokSc-gzGzoHsz","appKey":"QeD6ibBU3GKctfSty5fFG9Xz","path":"window.location.pathname","placeholder":"什么都不用填就可以评论啦(当然留个qq或者邮箱更好哦)","avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
